{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.1 선형 svm 분류\n",
    "\n",
    "caution!! SVM은 특성의 스케일에 민감 (support vector의 특성상 large margin을 추구하므로)-> 사이킷런의 StandardScaler 사용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 소프트 마진분류\n",
    "\n",
    "모든 샘플이 올바르게 분류 -> 하드 마진 분류(hard margin classification) : 모든 데이터를 선형적으로 분류해야 제대로 작동하고 이상치에 민감\n",
    "    \n",
    "마진 오류를 적절히 설정함 -> 소프트 마진 분류(soft margin classification) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scalar',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('linear_svc',\n",
       "                 LinearSVC(C=1, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "                           penalty='l2', random_state=None, tol=0.0001,\n",
       "                           verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "iris=datasets.load_iris()\n",
    "X=iris[\"data\"][:,(2,3)]\n",
    "y=(iris[\"target\"]==2).astype(np.float64)\n",
    "\n",
    "svm_clf=Pipeline([\n",
    "    (\"scalar\",StandardScaler()),\n",
    "    (\"linear_svc\",LinearSVC(C=1,loss=\"hinge\")),\n",
    "])\n",
    "\n",
    "svm_clf.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.predict([[5.5, 1.7]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 비선형 SVM 분류\n",
    "\n",
    "선형적으로 분류가 안되는 경우가 많으므로 비선형적인 피쳐를 추가해줘서 분류를 쉽게함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('poly_features',\n",
       "                 PolynomialFeatures(degree=3, include_bias=True,\n",
       "                                    interaction_only=False, order='C')),\n",
       "                ('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svm_clf',\n",
       "                 LinearSVC(C=10, class_weight=None, dual=True,\n",
       "                           fit_intercept=True, intercept_scaling=1,\n",
       "                           loss='hinge', max_iter=1000, multi_class='ovr',\n",
       "                           penalty='l2', random_state=None, tol=0.0001,\n",
       "                           verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_moons\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "X,y = make_moons(n_samples=100, noise=0.15)\n",
    "polynomial_svm_clf=Pipeline([\n",
    "    (\"poly_features\",PolynomialFeatures(degree=3)),\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"svm_clf\",LinearSVC(C=10,loss=\"hinge\"))\n",
    "]) \n",
    "# PolynomialFeatures-> n차항의 피쳐로 추가해 선형분류를 쉽게 만들어줌( 모든 머신러닝 알고리즘에서 잘통하나 피쳐가 늘어나므로 모델을 느리게 만든다.)\n",
    "polynomial_svm_clf.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2.1 다항식 커널"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scalar',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svm_clf',\n",
       "                 SVC(C=5, break_ties=False, cache_size=200, class_weight=None,\n",
       "                     coef0=1, decision_function_shape='ovr', degree=3,\n",
       "                     gamma='scale', kernel='poly', max_iter=-1,\n",
       "                     probability=False, random_state=None, shrinking=True,\n",
       "                     tol=0.001, verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "poly_kernel_svm_clf =Pipeline([\n",
    "    (\"scalar\",StandardScaler()),\n",
    "    (\"svm_clf\",SVC(kernel=\"poly\",degree=3,coef0=1,C=5)) # C-> 마진오류 \n",
    "])\n",
    "poly_kernel_svm_clf.fit(X,y)# degree=3 이므로 3차 다항식 커널을 사용해서 분류기를 훈련\n",
    "# coef0 는 모델이 높은 차수와 낮은 차수에 얼마나 영향을 받을 지 조정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.2.2 유사도 특성\n",
    "\n",
    "비선형적인 특성을 다루기 위해서 각 샘플이 특정 랜드마크(landmark)와 얼마나 닮았는지 측정하는 유사도 함수(similarity function)로 계산한 특성 추가\n",
    "\n",
    "유사도 함수는 가우시안(=radial basis function)로 보통 설정 , landmark는 데이터셋의 모든 샘플위에 랜드마크 설정\n",
    "\n",
    "-> 장점 :차원이 커지고 훈련셋이 선형으로 구분됨 \n",
    "    \n",
    "    단점: n개의 특성 m개의 데이터 -> m개의 특성, m개의 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('svm_clf',\n",
       "                 SVC(C=0.001, break_ties=False, cache_size=200,\n",
       "                     class_weight=None, coef0=0.0,\n",
       "                     decision_function_shape='ovr', degree=3, gamma=5,\n",
       "                     kernel='rbf', max_iter=-1, probability=False,\n",
       "                     random_state=None, shrinking=True, tol=0.001,\n",
       "                     verbose=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " ## 5.2.3 가우시안 RBF 커널\n",
    "rbf_kernel_svm_clf=Pipeline([\n",
    "    (\"scaler\",StandardScaler()),\n",
    "    (\"svm_clf\",SVC(kernel=\"rbf\", gamma=5, C=0.001))\n",
    "])\n",
    "rbf_kernel_svm_clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gamma: 증가할 시 -> 각 샘플의 영향 범위가 작아짐(심해지면 오버피팅)\n",
    "       \n",
    "       감소할 시 -> 더 일반적이게 됨 (심해지면 언더피팅)\n",
    "       \n",
    "선형커널->가우시안 커널-> 다른 커널\n",
    "\n",
    "일반적으로 다른 커널은 잘 사용되지않음\n",
    "\n",
    "문자열 커널(문자열 서브시퀀스 커널, 레벤슈타인 커널)이 텍스트 문서나 DNA 염기서열을 분류할떄 사용됨 \n",
    "\n",
    "(두 문자열의 유사도를 비교하는 함수) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.3 svm 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVR(C=1.0, dual=True, epsilon=1.5, fit_intercept=True,\n",
       "          intercept_scaling=1.0, loss='epsilon_insensitive', max_iter=1000,\n",
       "          random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "svm_reg =LinearSVR(epsilon=1.5)\n",
    "svm_reg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, cache_size=200, coef0=0.0, degree=2, epsilon=0.1, gamma='scale',\n",
       "    kernel='poly', max_iter=-1, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svm_poly_reg=SVR(kernel=\"poly\", degree=2, C=100, epsilon=0.1)\n",
    "\n",
    "svm_poly_reg.fit(X,y) # 다항으로 커널트릭 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
