{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 투표 기반 분류기 \n",
    "\n",
    "모든 분류기가 완벽하게 독립적이고 오차에 상관관계가 없을 경우 큰 수의 법칙에 의해 voting의 결과가 더 좋아진다!\n",
    "(극단적으로 51% 정확도를 가진 1000개의 분류기로 앙상블 모델을 구축한다면 75%의 정확도를 기대할 수 있습니다)\n",
    "\n",
    "다만 이런 가정은 현실에서는 같은 데이터로 훈련시키기 떄문에 이러한 가정이 맞지 않습니다.\n",
    "분류기들이 같은 종류의 오차를 만들기 떄문에 잘못된 클래스가 다수일 확률이 높아집니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression()\n",
    "rnd_clf = RandomForestClassifier()\n",
    "svm_clf = SVC()\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('lr',\n",
       "                              LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False)),\n",
       "                             ('rf',\n",
       "                              RandomForestClassifier(bootstrap=True,\n",
       "                                                     ccp_alpha=0.0,\n",
       "                                                     class_weight=None,\n",
       "                                                     cr...\n",
       "                                                     oob_score=False,\n",
       "                                                     random_state=None,\n",
       "                                                     verbose=0,\n",
       "                                                     warm_start=False)),\n",
       "                             ('svc',\n",
       "                              SVC(C=1.0, break_ties=False, cache_size=200,\n",
       "                                  class_weight=None, coef0=0.0,\n",
       "                                  decision_function_shape='ovr', degree=3,\n",
       "                                  gamma='scale', kernel='rbf', max_iter=-1,\n",
       "                                  probability=False, random_state=None,\n",
       "                                  shrinking=True, tol=0.001, verbose=False))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='hard',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voting_clf.fit=(X_train,y_train)\n",
    "voting_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression 0.864\n",
      "RandomForestClassifier 0.88\n",
      "SVC 0.896\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'tuple' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-6b8d073e8460>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlog_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting_clf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'tuple' object is not callable"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(voting_clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 배깅과 페이스팅\n",
    "vagging (bootstrap aggregating): 중복허용해서 리샘플링 (배깅만 한 예측기를 위해 같은 훈련샘플을 여러 번 샘플링 가능)\n",
    "\n",
    "pasting : 중복을 허용하지 않고 샘플링    \n",
    "    \n",
    "    \n",
    "개별 예측기는 원본 훈련세트로 훈련시킨 것보다 크게 편향되어 있지만 수집함수를 통과하면 편향과 분산이 모두 감소,\n",
    "\n",
    "일반적으로 앙상블의 결과는 원본 데이터셋으로 하나의 예측기를 훈련시킬때와 비교해 편향은 비슷하지만 분산은 줄어듭니다.    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.1 사이킷런의 배깅과 페이스팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf= BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples =100, bootstrap=True, n_jobs=-1)# n_jobs는 학스에 사용될 코어수를 지정(-1로 지정하면 모든 코어수 사용)\n",
    "bag_clf.fit(X_train,y_train)\n",
    "y_pred =bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bootstraping 은 각 예측기가 학습하는 서브셋의 다양성을 증가시키므로 배깅이 페이스팅보다 편향이 조금 더 높다. \n",
    "\n",
    "하지만 다양성을 추가하는 것은 예측기들의 상관관계를 줄이므로 앙상블의 분산을 감소시킨다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2.2 obb 평가"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "배깅을 사용할때 중복을 허용하므로 선택되지 않은 훈련샘플이 있습니다 \n",
    "\n",
    "이를 oob 샘플 (out of bag)이라고 합니다. 예측기마다 oob는 모두 다릅니다\n",
    "\n",
    "따라서 이를 검증셋으로 사용할 수 있고 앙상블의 평가는 각 예측기의 oob의 평가를 평균하여 얻습니다.\n",
    "\n",
    "BaggingClassifier에서 oob_score=True로 설정하면 훈련이 끝난후 자동으로 obb평가를 수행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf=BaggingClassifier(\n",
    "    DecisionTreeClassifier(),n_estimators=500,\n",
    "    bootstrap=True, n_jobs=-1, oob_score=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaggingClassifier(base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                        class_weight=None,\n",
       "                                                        criterion='gini',\n",
       "                                                        max_depth=None,\n",
       "                                                        max_features=None,\n",
       "                                                        max_leaf_nodes=None,\n",
       "                                                        min_impurity_decrease=0.0,\n",
       "                                                        min_impurity_split=None,\n",
       "                                                        min_samples_leaf=1,\n",
       "                                                        min_samples_split=2,\n",
       "                                                        min_weight_fraction_leaf=0.0,\n",
       "                                                        presort='deprecated',\n",
       "                                                        random_state=None,\n",
       "                                                        splitter='best'),\n",
       "                  bootstrap=True, bootstrap_features=False, max_features=1.0,\n",
       "                  max_samples=1.0, n_estimators=500, n_jobs=-1, oob_score=True,\n",
       "                  random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9013333333333333"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_score_ # oob에서의 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.888"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_pred=bag_clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3919598 , 0.6080402 ],\n",
       "       [0.3038674 , 0.6961326 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08235294, 0.91764706],\n",
       "       [0.44262295, 0.55737705],\n",
       "       [0.03553299, 0.96446701],\n",
       "       [0.98958333, 0.01041667],\n",
       "       [0.97536946, 0.02463054],\n",
       "       [0.7431694 , 0.2568306 ],\n",
       "       [0.01265823, 0.98734177],\n",
       "       [0.79444444, 0.20555556],\n",
       "       [0.82673267, 0.17326733],\n",
       "       [0.9558011 , 0.0441989 ],\n",
       "       [0.05780347, 0.94219653],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98369565, 0.01630435],\n",
       "       [0.95721925, 0.04278075],\n",
       "       [0.98837209, 0.01162791],\n",
       "       [0.01587302, 0.98412698],\n",
       "       [0.31360947, 0.68639053],\n",
       "       [0.90322581, 0.09677419],\n",
       "       [1.        , 0.        ],\n",
       "       [0.9895288 , 0.0104712 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.63684211, 0.36315789],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.14035088, 0.85964912],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.38829787, 0.61170213],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.2173913 , 0.7826087 ],\n",
       "       [0.34065934, 0.65934066],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00529101, 0.99470899],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00657895, 0.99342105],\n",
       "       [0.98550725, 0.01449275],\n",
       "       [0.90062112, 0.09937888],\n",
       "       [0.97948718, 0.02051282],\n",
       "       [0.95555556, 0.04444444],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08108108, 0.91891892],\n",
       "       [0.98305085, 0.01694915],\n",
       "       [0.0060241 , 0.9939759 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00518135, 0.99481865],\n",
       "       [0.98913043, 0.01086957],\n",
       "       [0.78606965, 0.21393035],\n",
       "       [0.375     , 0.625     ],\n",
       "       [0.9952381 , 0.0047619 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.70718232, 0.29281768],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.8908046 , 0.1091954 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.56149733, 0.43850267],\n",
       "       [0.16      , 0.84      ],\n",
       "       [0.61928934, 0.38071066],\n",
       "       [0.91525424, 0.08474576],\n",
       "       [0.        , 1.        ],\n",
       "       [0.14124294, 0.85875706],\n",
       "       [0.91666667, 0.08333333],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.03571429, 0.96428571],\n",
       "       [0.03381643, 0.96618357],\n",
       "       [0.36170213, 0.63829787],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.85164835, 0.14835165],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.27979275, 0.72020725],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95135135, 0.04864865],\n",
       "       [0.76300578, 0.23699422],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.19230769, 0.80769231],\n",
       "       [0.57303371, 0.42696629],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04022989, 0.95977011],\n",
       "       [0.47849462, 0.52150538],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03225806, 0.96774194],\n",
       "       [0.99462366, 0.00537634],\n",
       "       [0.30635838, 0.69364162],\n",
       "       [0.43915344, 0.56084656],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.25388601, 0.74611399],\n",
       "       [0.87700535, 0.12299465],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.80769231, 0.19230769],\n",
       "       [1.        , 0.        ],\n",
       "       [0.01796407, 0.98203593],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99514563, 0.00485437],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99484536, 0.00515464],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.94705882, 0.05294118],\n",
       "       [0.99438202, 0.00561798],\n",
       "       [0.02072539, 0.97927461],\n",
       "       [0.22340426, 0.77659574],\n",
       "       [0.9787234 , 0.0212766 ],\n",
       "       [0.26451613, 0.73548387],\n",
       "       [0.97790055, 0.02209945],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01388889, 0.98611111],\n",
       "       [0.67326733, 0.32673267],\n",
       "       [0.42372881, 0.57627119],\n",
       "       [0.44767442, 0.55232558],\n",
       "       [0.83707865, 0.16292135],\n",
       "       [0.94413408, 0.05586592],\n",
       "       [0.06521739, 0.93478261],\n",
       "       [0.78735632, 0.21264368],\n",
       "       [0.00515464, 0.99484536],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02234637, 0.97765363],\n",
       "       [0.97727273, 0.02272727],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01098901, 0.98901099],\n",
       "       [0.00543478, 0.99456522],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.95808383, 0.04191617],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.40659341, 0.59340659],\n",
       "       [0.27027027, 0.72972973],\n",
       "       [0.00543478, 0.99456522],\n",
       "       [0.        , 1.        ],\n",
       "       [0.29518072, 0.70481928],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.0104712 , 0.9895288 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98305085, 0.01694915],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00564972, 0.99435028],\n",
       "       [0.60869565, 0.39130435],\n",
       "       [0.91525424, 0.08474576],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99489796, 0.00510204],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.039801  , 0.960199  ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.02923977, 0.97076023],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01685393, 0.98314607],\n",
       "       [1.        , 0.        ],\n",
       "       [0.93785311, 0.06214689],\n",
       "       [0.78571429, 0.21428571],\n",
       "       [0.62941176, 0.37058824],\n",
       "       [0.        , 1.        ],\n",
       "       [0.13043478, 0.86956522],\n",
       "       [1.        , 0.        ],\n",
       "       [0.93888889, 0.06111111],\n",
       "       [0.97633136, 0.02366864],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00574713, 0.99425287],\n",
       "       [0.        , 1.        ],\n",
       "       [0.40571429, 0.59428571],\n",
       "       [0.87027027, 0.12972973],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.95789474, 0.04210526],\n",
       "       [0.        , 1.        ],\n",
       "       [0.26785714, 0.73214286],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.96022727, 0.03977273],\n",
       "       [0.87272727, 0.12727273],\n",
       "       [0.99459459, 0.00540541],\n",
       "       [0.        , 1.        ],\n",
       "       [0.0880829 , 0.9119171 ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03468208, 0.96531792],\n",
       "       [0.        , 1.        ],\n",
       "       [0.04651163, 0.95348837],\n",
       "       [1.        , 0.        ],\n",
       "       [0.7816092 , 0.2183908 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.90857143, 0.09142857],\n",
       "       [0.99411765, 0.00588235],\n",
       "       [0.15697674, 0.84302326],\n",
       "       [0.18877551, 0.81122449],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.23913043, 0.76086957],\n",
       "       [0.9787234 , 0.0212766 ],\n",
       "       [0.00546448, 0.99453552],\n",
       "       [1.        , 0.        ],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [0.        , 1.        ],\n",
       "       [0.47126437, 0.52873563],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00531915, 0.99468085],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.10227273, 0.89772727],\n",
       "       [0.08988764, 0.91011236],\n",
       "       [0.99438202, 0.00561798],\n",
       "       [0.01025641, 0.98974359],\n",
       "       [1.        , 0.        ],\n",
       "       [0.37696335, 0.62303665],\n",
       "       [0.06111111, 0.93888889],\n",
       "       [0.55913978, 0.44086022],\n",
       "       [0.59903382, 0.40096618],\n",
       "       [0.00581395, 0.99418605],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.56179775, 0.43820225],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.25      , 0.75      ],\n",
       "       [0.80288462, 0.19711538],\n",
       "       [0.05617978, 0.94382022],\n",
       "       [1.        , 0.        ],\n",
       "       [0.82233503, 0.17766497],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.08139535, 0.91860465],\n",
       "       [0.02590674, 0.97409326],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.92073171, 0.07926829],\n",
       "       [0.15789474, 0.84210526],\n",
       "       [0.94797688, 0.05202312],\n",
       "       [0.01030928, 0.98969072],\n",
       "       [0.625     , 0.375     ],\n",
       "       [0.06030151, 0.93969849],\n",
       "       [0.99473684, 0.00526316],\n",
       "       [0.82513661, 0.17486339],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.94857143, 0.05142857],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.29949239, 0.70050761],\n",
       "       [0.98888889, 0.01111111],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.01036269, 0.98963731],\n",
       "       [0.87709497, 0.12290503],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.75956284, 0.24043716],\n",
       "       [0.93814433, 0.06185567],\n",
       "       [1.        , 0.        ],\n",
       "       [0.640625  , 0.359375  ],\n",
       "       [0.5177665 , 0.4822335 ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.8742515 , 0.1257485 ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.865     , 0.135     ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.76744186, 0.23255814],\n",
       "       [0.1043956 , 0.8956044 ],\n",
       "       [0.4375    , 0.5625    ],\n",
       "       [0.23300971, 0.76699029],\n",
       "       [0.        , 1.        ],\n",
       "       [0.86956522, 0.13043478],\n",
       "       [0.85      , 0.15      ],\n",
       "       [0.00520833, 0.99479167],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98913043, 0.01086957],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02259887, 0.97740113],\n",
       "       [0.97849462, 0.02150538],\n",
       "       [0.95477387, 0.04522613],\n",
       "       [1.        , 0.        ],\n",
       "       [0.46987952, 0.53012048],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.98369565, 0.01630435],\n",
       "       [0.01666667, 0.98333333],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.93650794, 0.06349206],\n",
       "       [0.        , 1.        ],\n",
       "       [0.06666667, 0.93333333],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.00564972, 0.99435028],\n",
       "       [1.        , 0.        ],\n",
       "       [0.11494253, 0.88505747],\n",
       "       [0.        , 1.        ],\n",
       "       [0.00564972, 0.99435028],\n",
       "       [0.        , 1.        ],\n",
       "       [0.43455497, 0.56544503],\n",
       "       [0.05181347, 0.94818653],\n",
       "       [0.20121951, 0.79878049],\n",
       "       [1.        , 0.        ],\n",
       "       [0.98324022, 0.01675978],\n",
       "       [0.20098039, 0.79901961],\n",
       "       [0.98918919, 0.01081081],\n",
       "       [0.        , 1.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [1.        , 0.        ],\n",
       "       [0.97837838, 0.02162162],\n",
       "       [0.26857143, 0.73142857],\n",
       "       [0.99444444, 0.00555556],\n",
       "       [1.        , 0.        ],\n",
       "       [0.        , 1.        ],\n",
       "       [0.99512195, 0.00487805],\n",
       "       [0.        , 1.        ],\n",
       "       [0.02803738, 0.97196262],\n",
       "       [0.98901099, 0.01098901],\n",
       "       [1.        , 0.        ],\n",
       "       [0.03608247, 0.96391753],\n",
       "       [0.68062827, 0.31937173]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bag_clf.oob_decision_function_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.3 랜덤패치와 서브스페이스\n",
    "\n",
    "훈련 특성과 샘플을 모두 샘플링 하는 것을 랜덤 패치 방식(random patches method) 이라고 한다. (이미지와 같은 고차원의 데이터셋을 다루는데 유용)\n",
    "\n",
    "훈련 샘플을 모두 사용하고 (bootstrap=False, max_samples=1.0) 특성은 샘플링(bootsrap_features=True, max_features<1.0)하는 것을\n",
    "랜덤 서브스페이스 방식(random subspace method)이라고 한다\n",
    "\n",
    "-> 특성 샘플링은 더 다양한 예측기를 만들며 편향을 늘리는 대신 분산을 낮춰줍니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4 랜덤 포레스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, n_jobs=-1)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf=rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bagging classifier는 결정트리 의외의 모델에 적용할때 사용가능!\n",
    "\n",
    "랜덤 포레스트 알고리즘은 전체 특성 중 최선의 특성을 찾는 대신 무작위로 선택한 특성 후보중에서 최적의 특성을 찾는 식으로 무작위성을 더 주입합니다.\n",
    "\n",
    "이는 결국 트리를 더욱 다양하게 만들고 편향을 손해보는 대신 분산을 낮추어 전체적으로 더 휼륭한 모델을 만들어냅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf=BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_features=\"auto\", max_leaf_nodes=16),\n",
    "    n_estimators=500, max_samples=1.0, bootstrap=True, n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4.1 엑스트라 트리 \n",
    "\n",
    "랜덤 포레스트에서 트리를 만들 때 각 노드는 무작위로 특성의 서브셋을 만들어 분할에 사용합니다. \n",
    "트리를 더욱 무작위하게 만들기 위해 최적의 임계값을 찾는 대신 후보특성을 사용해 무작위로 분할한 다음 그 중에서 최상의 분할을 선택합니다.\n",
    "-> 익스트라 랜덤 트리 앙상블 (extremly ranodomized trees) 또는 extra trees 라고 한다. \n",
    "\n",
    "(편향이 늘어나지만 분산이 줄어든다. 모든 노드에서 최적의 임계값을 찾을 필요가 없으므로 랜덤 포레스트보다 엑스트라 트리가 훨씬 빠르다.)\n",
    "\n",
    "랜포와 엑스트라 트리 둘다 시도해서 비교해보고 그리드 서치로 하이퍼 파라미터 튜닝함\n",
    "\n",
    "ExtraClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.4.2 특성 중요도 \n",
    "\n",
    "사이킷런은 어떤 특성을 사용한 노드가 모든 트리에 걸쳐서 평균적으로 불순도를 얼마나 감소시켰는지를 기준으로 중요도를 측정\n",
    "\n",
    "-> 가중치 평균이며 각 노드의 가중치는 연관된 훈련샘플의 수와 같음\n",
    "\n",
    "학습이 끝난후 중요도가 전체 합이 1이 되도록 결과값을 정규화함 \n",
    "\n",
    "결정 트리의 중요도(전체합이 1이 되도록 정규화) = 현재 노드의 샘플 비율 x 불순도 - 왼쪽노드의 샘플 비율 x 불순도 - 오른쪽노드의 샘플 비율 x 불순도\n",
    "\n",
    "랜덤포레스트의 중요도 -> 각 결정트리의 특성 중요도를 모두 계산하여 더한 후 트리 개수로 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sepal length (cm) 0.09792045332721849\n",
      "sepal width (cm) 0.02286977670844244\n",
      "petal length (cm) 0.40378981429486427\n",
      "petal width (cm) 0.47541995566947487\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris=load_iris()\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500,n_jobs=-1)\n",
    "rnd_clf.fit(iris[\"data\"],iris[\"target\"])\n",
    "\n",
    "for name,score in zip(iris[\"feature_names\"], rnd_clf.feature_importances_):\n",
    "    print(name,score)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.5 부스팅\n",
    "\n",
    "약한 학습기를 여러개 연결하여 강한 학습기를 만드는 앙상블 방법\n",
    "\n",
    "(보통 잔차를 업데이트하여 다음 데이터셋을 구성)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5.1 에이다부스트\n",
    "\n",
    "알고리즘이 기반이 되는 첫번째 분류기를 훈련세트에 적합시키고 예측치를 만듬\n",
    "\n",
    "잘못 분류된 훈련샘플의 가중치를 상대적으로 높임,\n",
    "\n",
    "두번째 분류기는 업데이트된 가중치를 사용해 훈련세트에서 훈련하고 다시 예측을 만듬 \n",
    "\n",
    "위 방법을 계속 진행\n",
    "\n",
    "caution!! 연속된 학습 기법은 각 예측기가 이전 예측기의 훈련후 학습될 수 있기 때문에 병렬화(or 분할)을 할 수 없습니다. \n",
    "따라서 배깅이나 페이스팅만큼 확장성이 높지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R',\n",
       "                   base_estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                         class_weight=None,\n",
       "                                                         criterion='gini',\n",
       "                                                         max_depth=1,\n",
       "                                                         max_features=None,\n",
       "                                                         max_leaf_nodes=None,\n",
       "                                                         min_impurity_decrease=0.0,\n",
       "                                                         min_impurity_split=None,\n",
       "                                                         min_samples_leaf=1,\n",
       "                                                         min_samples_split=2,\n",
       "                                                         min_weight_fraction_leaf=0.0,\n",
       "                                                         presort='deprecated',\n",
       "                                                         random_state=None,\n",
       "                                                         splitter='best'),\n",
       "                   learning_rate=0.5, n_estimators=200, random_state=None)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "ada_clf=AdaBoostClassifier(\n",
    "    DecisionTreeClassifier(max_depth=1), n_estimators=200,\n",
    "    algorithm=\"SAMME.R\", learning_rate=0.5\n",
    ")\n",
    "ada_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.896"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred=ada_clf.predict(X_test)\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5.2 그래디언트 부스팅\n",
    "\n",
    "이전 예측기가 만든 잔여 오차(residual error)에 새로운 예측기를 학습시킵니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "X = np.random.rand(100, 1) - 0.5\n",
    "y = 3*X[:, 0]**2 + 0.05 * np.random.randn(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=2,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "tree_reg1 =DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=2,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2=y-tree_reg1.predict(X)\n",
    "tree_reg2 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg2.fit(X,y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(ccp_alpha=0.0, criterion='mse', max_depth=2,\n",
       "                      max_features=None, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                      random_state=None, splitter='best')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3=y2-tree_reg1.predict(X)\n",
    "tree_reg3 = DecisionTreeRegressor(max_depth=2)\n",
    "tree_reg3.fit(X,y3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X_new = np.array([[0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred = sum(tree.predict(X_new) for tree in (tree_reg1, tree_reg2, tree_reg3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.03991297])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=1.0, loss='ls', max_depth=2,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=3,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbrt=GradientBoostingRegressor(max_depth=2, n_estimators=3, learning_rate=1.0)\n",
    "gbrt.fit(X,y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning_rate는 매개변수가 각 트리의 기여정도를 조정한다\n",
    "이를 낮게 설정하면(많은 트리가 필요)일반적으로 예측 성능이 좋아집니다.\n",
    "\n",
    "->축소(shrinkage)라는 규제방법\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, ccp_alpha=0.0, criterion='friedman_mse',\n",
       "                          init=None, learning_rate=0.1, loss='ls', max_depth=2,\n",
       "                          max_features=None, max_leaf_nodes=None,\n",
       "                          min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                          min_samples_leaf=1, min_samples_split=2,\n",
       "                          min_weight_fraction_leaf=0.0, n_estimators=83,\n",
       "                          n_iter_no_change=None, presort='deprecated',\n",
       "                          random_state=None, subsample=1.0, tol=0.0001,\n",
       "                          validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X,y)\n",
    "\n",
    "gbrt=GradientBoostingRegressor(max_depth=2, n_estimators=120)\n",
    "gbrt.fit(X_train,y_train)\n",
    "\n",
    "errors = [mean_squared_error(y_val,y_pred)\n",
    "         for y_pred in gbrt.staged_predict(X_val)] # stagged_predict -> 훈련의 각 단계에서 아아상블에 의해 만들어진 예특기를 순회하는 반복자를 반환\n",
    "bst_n_estimators = np.argmin(errors)+1 # 최적 트리수!!\n",
    "\n",
    "gbrt_best=GradientBoostingRegressor(max_depth=2, n_estimators=bst_n_estimators )\n",
    "gbrt_best.fit(X_train, y_train)\n",
    "# warm_start =True 로 설정하면 fit() 메서드가 호출될떄 기존 트리를 유지하고 훈련을 추가할 수 있도록 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2, warm_start=True)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "error_going_up = 0\n",
    "for n_estimators in range(1, 120):\n",
    "    gbrt.n_estimators = n_estimators\n",
    "    gbrt.fit(X_train, y_train)\n",
    "    y_pred = gbrt.predict(X_val)\n",
    "    val_error = mean_squared_error(y_val, y_pred)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        error_going_up = 0\n",
    "    else:\n",
    "        error_going_up += 1\n",
    "        if error_going_up == 5:\n",
    "            break  # early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GradientBoostingRegressor는 각 트리가 훈련될때 사용할 훈련 샘플의 비율을 지정할 수 있습니다\n",
    "\n",
    "(sub_sample = 0.25라고 하면 각 트리는 무작위로 선택된 25%의 훈련샘플로 학습됨)\n",
    "\n",
    "-> 이라한 기법을 확률적 그레디언트 부스팅 기법이라 함\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:06:34] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "xgb_reg=xgboost.XGBRegressor()\n",
    "xgb_reg.fit(X_train,y_train)\n",
    "y_pred = xgb_reg.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:07:53] WARNING: C:/Jenkins/workspace/xgboost-win64_release_0.90/src/objective/regression_obj.cu:152: reg:linear is now deprecated in favor of reg:squarederror.\n",
      "[0]\tvalidation_0-rmse:0.308403\n",
      "Will train until validation_0-rmse hasn't improved in 2 rounds.\n",
      "[1]\tvalidation_0-rmse:0.280384\n",
      "[2]\tvalidation_0-rmse:0.255261\n",
      "[3]\tvalidation_0-rmse:0.232697\n",
      "[4]\tvalidation_0-rmse:0.211968\n",
      "[5]\tvalidation_0-rmse:0.192675\n",
      "[6]\tvalidation_0-rmse:0.177464\n",
      "[7]\tvalidation_0-rmse:0.163445\n",
      "[8]\tvalidation_0-rmse:0.151159\n",
      "[9]\tvalidation_0-rmse:0.140248\n",
      "[10]\tvalidation_0-rmse:0.130624\n",
      "[11]\tvalidation_0-rmse:0.121576\n",
      "[12]\tvalidation_0-rmse:0.113691\n",
      "[13]\tvalidation_0-rmse:0.106864\n",
      "[14]\tvalidation_0-rmse:0.101159\n",
      "[15]\tvalidation_0-rmse:0.095552\n",
      "[16]\tvalidation_0-rmse:0.091277\n",
      "[17]\tvalidation_0-rmse:0.087887\n",
      "[18]\tvalidation_0-rmse:0.084786\n",
      "[19]\tvalidation_0-rmse:0.081612\n",
      "[20]\tvalidation_0-rmse:0.079539\n",
      "[21]\tvalidation_0-rmse:0.077531\n",
      "[22]\tvalidation_0-rmse:0.076274\n",
      "[23]\tvalidation_0-rmse:0.074814\n",
      "[24]\tvalidation_0-rmse:0.073593\n",
      "[25]\tvalidation_0-rmse:0.072558\n",
      "[26]\tvalidation_0-rmse:0.071551\n",
      "[27]\tvalidation_0-rmse:0.070612\n",
      "[28]\tvalidation_0-rmse:0.070049\n",
      "[29]\tvalidation_0-rmse:0.069537\n",
      "[30]\tvalidation_0-rmse:0.069231\n",
      "[31]\tvalidation_0-rmse:0.068553\n",
      "[32]\tvalidation_0-rmse:0.068576\n",
      "[33]\tvalidation_0-rmse:0.068003\n",
      "[34]\tvalidation_0-rmse:0.067923\n",
      "[35]\tvalidation_0-rmse:0.068006\n",
      "[36]\tvalidation_0-rmse:0.06775\n",
      "[37]\tvalidation_0-rmse:0.06769\n",
      "[38]\tvalidation_0-rmse:0.067354\n",
      "[39]\tvalidation_0-rmse:0.067329\n",
      "[40]\tvalidation_0-rmse:0.066902\n",
      "[41]\tvalidation_0-rmse:0.066472\n",
      "[42]\tvalidation_0-rmse:0.066557\n",
      "[43]\tvalidation_0-rmse:0.066532\n",
      "Stopping. Best iteration:\n",
      "[41]\tvalidation_0-rmse:0.066472\n",
      "\n"
     ]
    }
   ],
   "source": [
    "xgb_reg.fit(X_train, y_train,\n",
    "                eval_set=[(X_val, y_val)], early_stopping_rounds=2)\n",
    "y_pred = xgb_reg.predict(X_val)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
